Humanoid-v2
python3 run_expert.py experts/Humanoid-v2.pkl Humanoid-v2 --num_rollouts=100
mean return 10403.88893954622
std of return 62.57711942277168
python3 train_imitation.py Humanoid-v2-100rollouts.pkl --epoch 30 --save
python3 run_imitation.py Humanoid-v2-100rollouts-epoch30.ckpt --render
does not work
python3 run_imitation.py Humanoid-v2-100rollouts-epoch30.ckpt --num_rollouts=100
return mean:  654.9366444726442
return_std:  206.359680879123

dagger
python3 train_imitation.py Humanoid-v2-10rollouts.pkl --dagger  --expert_policy_file experts/Humanoid-v2.pkl\
    --epoch 3 --dagger_iterations 10 --dagger_num_rollouts 10 --learning_rate 0.001 --save
return mean:  303.85772961746505
return_std:  49.020633901239165

python3 train_imitation.py Humanoid-v2-100rollouts.pkl --dagger  --expert_policy_file experts/Humanoid-v2.pkl\
    --epoch 10 --dagger_iterations 30 --dagger_num_rollouts 30 --learning_rate 0.1 --save
after 9 interation:
return mean:  1035.276007824771
return_std:  423.57152866123363

python3 run_expert.py experts/Humanoid-v2.pkl Humanoid-v2 --num_rollouts=100 --max_timestep 300 --save
mean return 2716.929066027717
std of return 33.24113594407771
python3 train_imitation.py Humanoid-v2-100rollouts.pkl --dagger  --expert_policy_file experts/Humanoid-v2.pkl\
    --epoch 10 --dagger_iterations 30 --dagger_num_rollouts 100 --learning_rate 0.1 --save
return mean:  908.4416545818135
return_std:  447.48943137937647
return_means [400.5712832253967, 385.200101977222, 431.2067663695502, 413.422872661094, 546.1990703983786, 568.321142012635, 523.6652143407831, 659.428825900325, 574.2348630996898, 739.0398838421123, 678.471642053831, 820.5632155161444, 716.3401470755454, 837.0780588123721, 785.6335519724079, 800.4475105411373, 1002.9129803075755, 848.6959934879244, 977.4762397390145, 894.2787033734785, 899.4644967892174, 922.0201038760993, 963.8360369660643, 851.7148139718604, 960.0818840083745, 849.6758747293904, 920.3174492641355, 985.8476403697645, 1019.0730035355218, 908.4416545818135]
return_stds [107.81755538935715, 128.98183920254175, 157.06921801250968, 144.67086302529728, 276.29974822769964, 250.49772061087978, 228.89906515119242, 349.7077176104882, 248.7048183507784, 349.1003055838679, 224.25529826890283, 342.5057094594247, 189.21839513769504, 394.7333735085451, 282.58647924462036, 304.0672660926757, 461.5450213120692, 306.3481207672108, 442.21037594643116, 362.399249271037, 327.19015874756593, 345.0736653717187, 376.3698690841475, 299.6897890093158, 404.7513274474197, 288.59801606640156, 357.2541462211451, 384.529583092882, 440.8848108999356, 447.48943137937647]
Model saved in saved_models/Humanoid-v2-100rollouts-dagger-30iter-100dagger_rollouts-epoch10.ckpt

python3 run_imitation.py Humanoid-v2-100rollouts-dagger-30iter-100dagger_rollouts-epoch10.ckpt --render
can run a couple of steps
python3 run_imitation.py Humanoid-v2-100rollouts-dagger-30iter-100dagger_rollouts-epoch10.ckpt --max_timestep 300 --num_rollouts=100


Reacher
python3 run_expert.py experts/Reacher-v2.pkl Reacher-v2 --num_rollouts=1000 --save
mean return -3.885396356465998
std of return 1.7641796953187314

python3 train_imitation.py Reacher-v2-1000rollouts.pkl --epoch 300 --save
Training loss:  9.84617752671641e-06
Test loss:  8.673427e-06

python3 run_imitation.py Reacher-v2-1000rollouts-epoch200.ckpt --num_rollouts=1000
return mean:  -3.9589514250825335
return_std:  1.7107000996680581

expert qual eval
python3 run_expert.py experts/Reacher-v2.pkl Reacher-v2 --render

imitation qual eval
python3 run_imitation.py Reacher-v2-1000rollouts-epoch200.ckpt --render
mostly works

dagger training
python3 train_imitation.py Reacher-v2-100rollouts.pkl --dagger --expert_policy_file experts/Reacher-v2.pkl\
    --epoch 30 --dagger_iterations 30 --dagger_num_rollouts 100 --save
return_means [-11.72982351641989, -9.006079161810042, -6.257192192647782, -5.166162900572425, -5.084228871142994, -4.84061297198008, -4.758946023305666, -4.4255842738966775, -4.111627881527015, -3.952034098594203, -4.1357565805662375, -3.821227044617403, -4.225861591516742, -3.664004979119558, -4.317669640469875, -4.164024729039202, -4.116547375655081, -3.7908259893492398, -4.09064302428576, -4.100254837519747, -4.295146585800017, -4.148900106626015, -3.8362719302749326, -3.9910695060002643, -3.576840453461433, -3.993259437330449, -3.884668878727931, -3.937397779184709, -3.8732323143420455, -3.7987571881487487]
last return: -3.7987571881487487
Model saved in saved_models/Reacher-v2-100rollouts-dagger-30iter-100dagger_rollouts-epoch30.ckpt

dagger qual eval
python3 run_imitation.py Reacher-v2-100rollouts-dagger-30iter-100dagger_rollouts-epoch30.ckpt --render
works!

python3 run_imitation.py Reacher-v2-100rollouts-dagger-30iter-100dagger_rollouts-epoch30.ckpt --num_rollouts=1000
return mean:  -3.954657875591113
return_std:  1.7395147158157167

more dagger training
python3 train_imitation.py Reacher-v2-100rollouts.pkl --dagger --expert_policy_file experts/Reacher-v2.pkl\
    --epoch 30 --dagger_iterations 100 --dagger_num_rollouts 100 --save

python3 train_imitation.py Reacher-v2-100rollouts.pkl --dagger --expert_policy_file experts/Reacher-v2.pkl\
    --epoch 30 --dagger_iterations 50 --dagger_num_rollouts 100 --save
Training loss:  8.554768533807979e-09
Test loss:  0.00058409537
Model saved in saved_models/Reacher-v2-100rollouts-dagger-100iter-1000dagger_rollouts-epoch30.ckpt
return_means [-84.4583389245696, -8.003302201394215, -8.342315445872668, -8.459375614814508, -7.043547240070946, -5.877637897407999, -4.849069867752514, -5.06632233237241, -4.3977646761435185, -4.345090619744086, -4.290720512169286, -4.065451261106158, -4.541701142050745, -4.140219927826809, -4.115188123528627, -4.081897593323734, -4.056467473594981, -4.13651637407329, -4.285124857738326, -4.017402955170154, -4.136150979376374, -3.942919554650127, -3.968457642633166, -4.012118954322101, -4.040274027632363, -4.078916680543563, -3.9754286346867715, -3.9800650106487576, -4.151030437594986, -3.930434362463273, -4.018974463264911, -4.105073842784631, -4.050843296521773, -4.157610374915077, -4.069296751722468, -4.058913509853479, -3.789189256037049, -4.071200251846695, -3.958473952196765, -4.144303991282974, -3.8680483051484993, -3.9452639669085046, -4.001444404805945, -4.020696466873737, -4.0242585821432675, -3.8604497399846647, -4.2618879050712195, -4.137612740683215, -3.9563795230732235, -4.077162480357113, -3.977077006326383, -4.003781904069991, -4.016574076994999, -3.918064627322077, -4.020085641457309, -4.004585765208841, -4.105327167680259, -3.8118411074514156, -3.928841087078752, -3.9336697790664035, -3.930409017345621, -4.086291624475241, -3.9340803209313013, -3.901142379172108, -4.083075615374858, -3.830473322746427, -3.886789036481727, -3.8661713552874737, -3.9804774755305927, -3.9190388581266355, -3.9872953884202187, -3.8864506363656983, -4.040574449217479, -3.9555891083729495, -3.9628597107135475, -3.9467918426408217, -3.9727174584710405, -4.019249134025847, -3.8978706845862425, -3.954153509350998, -3.923287859573507, -3.9538143292149988, -3.9281608211526375, -3.988570655056571, -4.013639355734739, -3.856498612862827, -4.136660533215589, -3.9360362588250655, -3.8723904259241726, -3.883540618257735, -4.195593804551573, -3.98365601886093, -3.8856734503022747, -3.9794964492956186, -3.8741965910388223, -3.9953773381199302, -3.90566682146086, -3.9895005206459158, -4.173272602936397, -4.061187794742455]
return_stds [3.577481932376201, 3.6184249212543493, 2.269307890083014, 2.2322971770932925, 2.431775248300428, 2.276802381049929, 1.9923227216201849, 1.7989949560701264, 1.9104839828625468, 1.7219701947138024, 1.6265009199945997, 1.7403605044997152, 1.8694560906966062, 1.803832699881306, 1.7032491652935227, 1.7371374509537982, 1.763446940735172, 1.7961378799370622, 1.8133267322738624, 1.6976287582654908, 1.6645233984612318, 1.7282183479436615, 1.6763984388178852, 1.7045538662696689, 1.693615335348983, 1.7268057169097843, 1.6954683084510496, 1.7424970267319948, 1.7091978666740062, 1.714928307761071, 1.7105339085341849, 1.6750744152956922, 1.7679331720773726, 1.7051255878592344, 1.7437631460722374, 1.7411556508366528, 1.6056516217779326, 1.6801862256872346, 1.7399703853252229, 1.7036830130275487, 1.7310140075167546, 1.7157320762654238, 1.7447820508538694, 1.7187331036674882, 1.7355958799895697, 1.66803077890667, 1.7653879060283406, 1.785374946650384, 1.7375574804425415, 1.7941460248380978, 1.709682119014294, 1.6559685783066769, 1.703848270472449, 1.7198494684177532, 1.786736427709244, 1.746721950099709, 1.6772565988926977, 1.6507449427724945, 1.7110388264534424, 1.6755798857950248, 1.7312214521113716, 1.764040337246455, 1.711389680729621, 1.7161248617450813, 1.7529657763720026, 1.6893297396666376, 1.7421841286944522, 1.7431873320230613, 1.7080071390670908, 1.7175557218266193, 1.7669728066605683, 1.74568314357312, 1.7302378683606991, 1.6705773373027182, 1.7582927942213071, 1.7402162466957651, 1.7754714122115387, 1.749261824457846, 1.664291020635815, 1.742764102624255, 1.7118898659267745, 1.6997756145169354, 1.7176372371969557, 1.6691655896436675, 1.6900690817129564, 1.665962453652075, 1.7257196150573493, 1.7662746759630457, 1.7210166815989476, 1.7603356017404106, 1.7622740077918526, 1.7114084630880837, 1.6994841518062658, 1.7544060464134354, 1.7666760269897923, 1.7129709522868346, 1.736486738132492, 1.7118506329269851, 1.787815289284095, 1.7112949328857383]
last mean: -4.061187794742455

python3 run_imitation.py Reacher-v2-100rollouts-dagger-100iter-1000dagger_rollouts-epoch30.ckpt --num_rollouts=1000
return mean:  -3.9471915319042257
return_std:  1.7432762944310172


Ant
python3 run_expert.py experts/Ant-v2.pkl Ant-v2 --num_rollouts=1000 --save
mean return 4764.516861476054
std of return 427.21418527562446
python3 train_imitation.py Ant-v2-1000rollouts.pkl --epoch 300 --save
Training loss:  8.410756204802623e-05
Test loss:  0.00014473159
Model saved in saved_models/Ant-v2-1000rollouts-epoch300.ckpt
python3 run_imitation.py Ant-v2-1000rollouts-epoch300.ckpt --render
works!
python3 run_imitation.py Ant-v2-1000rollouts-epoch300.ckpt --num_rollouts=100
return mean:  4679.182153004228
return_std:  584.4141839826455

